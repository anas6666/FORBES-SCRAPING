name: Scrape and Upload to S3

on:
  schedule:
    - cron: '0 0 * * 1' # Every Monday at 00:00
  workflow_dispatch: # For manual triggers

jobs:
  scrape_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run scraping script
        run: python Forbes_Codes.py

      - name: Check if JSON exists
        run: |
          if [ ! -f billionaires_data.json ]; then
            echo "JSON file not found!"
            exit 1
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_FORBES }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_FORBES }}
          aws-region: us-east-1

      - name: Upload JSON to S3
        run: aws s3 cp billionaires_data.json s3://rawdatabillionnaire/billionaires_data.json
